{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: making sense of language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the basics of NLP\n",
    "- Topic identification\n",
    "- Text classification\n",
    "\n",
    "NLP applications include:\n",
    "- Chatbots\n",
    "- Translation\n",
    "- Sentiment analysis\n",
    "- ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- strings with a special syntax\n",
    "- allow us to match patterns in other strings\n",
    "\n",
    "applications:\n",
    "- find all web links in a document\n",
    "- parse email addresses, remove/replace unwanted characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match('abc', 'abcdef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 2), match='hi'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_regex = '\\w+'\n",
    "re.match(word_regex, 'hi there!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common regex patterns\n",
    " pattern         matches           example\n",
    "   \\w+            word             'Magic'\n",
    "   \\d             digit               9\n",
    "   \\s             space              ' '\n",
    "   .*           wildcard         'username74'\n",
    " + or *       greedy match        'aaaaaa'\n",
    "   \\S          not space         'no_spaces'\n",
    " [a-z]       lowercase group      'abcdefg'\n",
    "\n",
    "\n",
    "+ at least once\n",
    "* 1 or more times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: prefix your regex patterns with r\n",
    "\"\\n\" in Python is used to indicate a new line, \n",
    "but if you use the r prefix, \n",
    "it will be interpreted as the raw string \"\\n\" \n",
    "that is, the character \"\\\" followed by the character \"n\" - and not as a new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re module\n",
    "- split: split a string on regex\n",
    "- findall: find all patterns in a string\n",
    "- search: search for a pattern\n",
    "- match: match an entire string or substring based on a pattern (looks for match in the beggining)\n",
    "\n",
    "put pattern first, and string second\n",
    "may return an iterator, string, or match object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Split', 'on', 'spaces.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('\\s+', 'Split on spaces.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"Let's write RegEx!  Won't that be fun?  I sure think so.  Can you find 4 sentences?  Or perhaps, all 19 words?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's write RegEx\", \"  Won't that be fun\", '  I sure think so', '  Can you find 4 sentences', '  Or perhaps, all 19 words', '']\n"
     ]
    }
   ],
   "source": [
    "# Write a pattern to match sentence endings: sentence_endings\n",
    "sentence_endings = r\"[.?!]\"\n",
    "\n",
    "# Split my_string on sentence endings and print the result\n",
    "print(re.split(sentence_endings, my_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Let', 'RegEx', 'Won', 'Can', 'Or']\n"
     ]
    }
   ],
   "source": [
    "# Find all capitalized words in my_string and print the result\n",
    "capitalized_words = r\"[A-Z]\\w+\"\n",
    "print(re.findall(capitalized_words, my_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's\", 'write', 'RegEx!', \"Won't\", 'that', 'be', 'fun?', 'I', 'sure', 'think', 'so.', 'Can', 'you', 'find', '4', 'sentences?', 'Or', 'perhaps,', 'all', '19', 'words?']\n"
     ]
    }
   ],
   "source": [
    "# Split my_string on spaces and print the result\n",
    "spaces = r\"\\s+\"\n",
    "print(re.split(spaces,my_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4', '19']\n"
     ]
    }
   ],
   "source": [
    "# Find all digits in my_string and print the result\n",
    "digits = r\"\\d+\"\n",
    "print(re.findall(digits,my_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tati\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#natural language toolkit\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'there', '!']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk tokenizers\n",
    "word_tokenize: tokenize a document into words\n",
    "sent_tokenize: tokenize a document into sentences\n",
    "regexp_tokenize: tokenize based on a regular expression pattern\n",
    "TweetTokenizer: separate hashtags, mentions and lots of exclamation points!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory : C:\\Users\\tati\\Documents\\tera\\NLP\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Directory :\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data\\grail.txt\", encoding=\"utf-8\") as grail: \n",
    "    scene_one = grail.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split scene_one into sentences: sentences\n",
    "sentences = sent_tokenize(scene_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARTHUR', ':', 'It', 'is', 'I', ',', 'Arthur', ',', 'son', 'of', 'Uther', 'Pendragon', ',', 'from', 'the', 'castle', 'of', 'Camelot', '.']\n"
     ]
    }
   ],
   "source": [
    "# Use word_tokenize to tokenize the fourth sentence: tokenized_sent\n",
    "tokenized_sent = word_tokenize(sentences[3])\n",
    "print(tokenized_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Father', 'Dragon', 'throwing', 'fifty', 'private', 'nasty', 'recover', 'routines', 'accent', 'Enchanter', 'lambs', 'previous', 'woods', 'whoever', 'Psalms', 'None', 'enemies', 'whose', 'arm', 'spoken', 'seek', 'Could', 'here', 'comin', 'dona', 'jump', 'Winter', 'Really', 'PARTY', 'Fine', 'ni', 'smashing', 'tiny-brained', 'lobbed', 'sequin', 'bang', 'suffice', 'headed', 'Silence', 'Message', 'set', 'English', 'killed', 'p', 'making', 'face', 'worried', 'sovereign', 'hast', 'Meanwhile', 'must', 'terribly', 'intermission', 'laurels', 'Princess', 'basic', 'ratios', 'witches', 'tit', 'Chickennn', 'kicked', 'pig-dogs', 'Follow', 'CHARACTERS', 'Chicken', 'Autumn', 'varletesses', 'Tim', 'father', 'taken', 'summon', 'heads', 'move', 'since', 'Robin', 'breakfast', 'MAN', '...', \"'old\", 'model', 'k-nnnnniggets', 'keepers', 'Galahad', 'Castle', 'elbows', 'autocracy', 'footwork', \"e'er\", 'force', 'major', 'entering', 'problem', 'hidden', 'sniff', '15', 'another', 'pussy', 'perpetuates', 'moistened', 'successful', 'from', 'music', 'smelt', \"'Til\", '!', 'dunno', 'Right', 'Peril', 'thanks', 'peril', 'enjoying', 'ha', 'Providence', 'earthquakes', 'pram', 'At', '20', 'amazes', 'listen', 'Fiends', 'change', 'Tale', 'number', 'newt', 'y', 'medieval', 'general', ';', 'dancing', 'er', 'confuse', 'HEADS', 'bosom', 'Stay', 'already', 'Pure', 'lucky', 'Ulk', 'requiem', 'strewn', 'More', 'Holy', 'nothing', 'tie', 'shrubber', 'suffered', 'Eternal', 'do', 'chickened', 'My', 'history', 'j', 'weighs', 'temperate', 'Between', 'own', 'mer', '10', 'ridden', 'Auuuuuuuugh', 'bladders', 'too', 'taunting', 'watch', 'blondes', 'individually', 'Lancelot', '24', 'unclog', 'brought', 'drink', 'meant', 'die', 'see', 'Iiiives', 'Idiom', 'Saint', 'Gawain', 'mortally', 'impeccable', 'velocity', 'although', 'Excalibur', 'discovered', 'GIRLS', 'week', 'behold', 'God', 'foot', 'invincible', 'Haw', 'gave', 'fled', 'beautiful', 'rather', 'argue', 'purest', 'Bristol', 'two-level', 'Look', 'Man', 'sacred', 'worthy', 'aunties', 'because', 'Quiet', 'coconuts', 'while', 'yeah', 'armor', 'a', 'way', 'weather', 'Bon', 'certain', 'Ay', 'hell', '(', 'police', 'stretched', 'grail', 'crossed', '16', 'ungallant', 'seen', 'got', 'happens', 'An', 'Did', 'side', 'higher', 'warmer', 'doctors', 'sort', 'danger', 'carried', 'runes', 'Quite', 'tonight', 'show', 'king', 'whether', 'wooden', 'Picture', 'rest', 'purpose', \"'aaggggh\", 'favorite', 'Shh', 'gurgle', 'jokes', 'A', 'relics', 'imperialist', 'lobbest', 'THE', 'When', 'giggle', 'gay', 'personally', 'telling', 'when', 'testicles', 'Yeaaah', 'creature', 'spirit', '5', 'It', 'nor', 'like', 'mightiest', 'fire', 'In', 'direction', 'rewr', 'twenty-four', 'call', 'further', 'Bring', 'Explain', 'twong', 'yel', 'Speak', 'Greetings', 'special', 'penalty', 'totally', 'Exactly', 'wart', 'coconut', 'pounds', 'smack', 'refuse', 'progress', 'Armaments', 'Then', 'knight', 'King', 'Neee-wom', 'fortune', 'We', 'strand', 'adversary', 'gon', 'kill', 'France', 'Knight', 'ours', 'Well', 'whop', 'Alright', 'dressed', 'using', 'Build', 'praised', 'quack', 'upon', 'Thppppt', 'happy', 'Assyria', 'tart', 'the-not-quite-so-brave-as-Sir-Lancelot', 'pissing', 'big', 'Ages', 'sharp', 'SENTRY', 'dramatic', 'van', 'Umhm', 'spooky', 'suddenly', 'earth', 'Grenade', 'she', 'out', 'wherein', 'silence', 'eats', 'trade', 'inside', 'whinny', 'living', 'longer', 'friend', 'Roger', 'Piglet', 'end', 'Seek', 'reared', 'simple', 'threw', 'Anybody', 'all', 'nice-a', 'hamster', 'shelter', 'ratified', 'kick', 'freedom', 'bitching', 'scratch', 'FRENCH', 'Burn', 'makes', 'Victory', 'obviously', 'considerable', 'angels', 'Mine', 'aside', 'tail', 'frozen', 'Arimathea', 'want', \"'aaaah\", 'draw', 'setting', 'Knights', 'Oooh', 'false', 'song', 'ZOOT', 'filth', 'but', 'cast', 'vouchsafed', 'compared', 'NARRATOR', 'snuff', 'interested', 'surprise', 'ceremony', 'daft', 'favor', \"'round\", 'scarper', 'cart', 'bite', 'Aauuuves', 'Hyy', 'pointy', 'work', 'grenade', 'questions', 'SIR', 'wayy', 'design', 'feint', 'hacked', 'temptress', 'where', 'would', 'advancing', 'so-called', 'marrying', 'chosen', 'Rather', 'think', 'lady', 'scott', 'ere', 'tops', 'triumphs', 'cereals', 'expect', 'many', 'Excuse', 'awaaay', 'Cornwall', 'gentle', 'grin', 'burn', 'can', 'Shrubberies', 'Aaaaaaaah', 'apart', 'haw', 'chickening', 'clue', \"'til\", 'legally', \"'S\", 'duty', 'mercy', 'Rheged', 'people', 'boys', 'Would', 'reached', 'dark', 'without', 'their', 'Open', 'excepting', 'PATSY', 'bravely', 'gained', 'sank', 'Which', 'minstrels', 'pound', 'executive', 'Bread', 'feast', 'ready', 'shrubbery', 'BORS', 'necessary', 'finds', 'Riiight', 'wings', 'automatically', \"'ni\", 'Peng', 'honored', 'or', 'kneeling', 'Anthrax', 'Make', 'Packing', 'Lead', 'looked', 'idea', 'someone', 'Y', 'fly', 'anyone', 'buggering', 'ha..', 'ROBIN', 'absolutely', 'quick', 'ounce', 'Do', 'Your', 'trumpets', 'blow', 'completely', 'scared', 'Over', 'kings', 'send', 'Hoo', 'bells', 'which', 'discovers', 'pulp', 'wonderful', 'signifying', 'Oooohoohohooo', 'Hiyah', 'Today', 'dare', 'used', 'bits', 'walk', 'Shall', 'sneaking', 'request', 'thou', '8', 'Black', 'lie', 'cop', 'thud', '2', 'stand', 'By', 'slash', 'PRINCE', 'Try', 'knees-bent', 'rhymes', 'SECOND', 'All', 'make', 'color', 'How', 'home', 'long', 'GUEST', 'yelling', 'soon', 'than', 'resting', 'Forgive', 'k-niggets', 'tackle', 'away', 'occasion', 'bit', 'same', 'horse', 'clank', 'Am', \"'\", 'moment', 'herring', 'ho', 'curtains', 'ride', 'throat', 'ALL', 'glory', 'unarmed', 'offensive', 'CONCORDE', 'my', 'Our', 'welcome', 'language', 'fine', 'as', 'closest', 'rich', 'GUARD', 'Brave', 'Aauuggghhh', 'large', 'smashed', 'convinced', 'animal', 'brunettes', 'leads', 'easily', 'Hooray', 'Leaving', 'ai', 'Aagh', 'Attila', 'aptly', 'kind', 'husk', 'nine', 'Remove', 'between', 'STUNNER', 'quarrel', 'spanked', 'shalt', 'Consult', 'behaviour', 'Prince', 'manner', 'dressing', 'dragging', 'Thsss', 'types', 'guest', 'wave', 'next', 'suppose', 'Bors', 'proceed', 'walking', 'commune', 'Perhaps', 'bet', 'master', 'Unfortunately', 'Aramaic', 'case', 'fight', 'emperor', 'bring', 'illustrious', 'dictatorship', 'assault', 'bleeder', 'k-nnniggets', 'fought', 'crone', 'huge', 'remain', 'Or', 'valor', 'folk', 'Apples', 'cadeau', 'made', 'dance', 'explain', 'proved', 'daughter', 'basis', 'Yes', 'anarcho-syndicalist', 'Aaaah', 'cartoon', 'snows', 'flights', 'himself', 'three', 'open', 'Ow', 'later', 'matter', 'clang', 'society', 'halves', 'did', 'clop', 'SOLDIER', '1', 'Ha', 'be', 'chanting', 'breadth', 'towards', 'two', 'warm', 'expensive', 'Five', 'stab', 'Twenty-one', 'names', 'Jesus', 'B', 'zone', 'horrendous', 'excuse', 'Loimbard', 'may', 'stress', 'sword', 'Erm', 'peasant', 'lives', 'WITCH', 'purely', 'dad', 'Supreme', 'frontal', 'taunt', 'MONKS', 'May', 'Launcelot', 'treat', 'system', 'stuffed', 'Quickly', 'mistake', 'Hang', 'after', 'once', '13', 'Put', 'chu', 'anywhere', 'ruffians', 'shall', 'daring', 'thonk', 'some', 'anyway', 'Found', 'against', 'Sorry', \"'T\", 'join', 'pack', 'rock', \"'re\", 'guarded', ')', 'Quick', 'stew', 'thy', 'looney', 'everyone', \"'m\", 'on', '14', 'Ewing', 'affairs', 'relax', 'legendary', 'um', 'Aaauggh', 'stops', 'deeds', 'carry', 'OLD', 'bones', 'sign', 'Beyond', 'centuries', 'found', 'seemed', 'only', 'Camelot', 'LEFT', 'always', 'Skip', 'distress', 'fold', 'GOD', 'deal', 'know', 'swallow', 'yellow', 'Alice', 'Christ', 'vital', 'gone', 'Agh', 'Far', 'Ask', 'majority', 'Tell', 'had', 'Arthur', 'became', 'Say', 'keep', 'terrible', 'KNIGHT', 'Gorge', 'luck', 'heart', 'sworn', 'pay', '?', 'live', 'lot', '[', 'jam', 'pure', 'identical', 'finest', 'oui', 'aloft', 'vain', 'burned', 'quiet', 'Please', 'binding', 'one', 'being', 'shrubberies', 'Swamp', 'allowed', 'legs', 'lived', 'shivering', 'continue', 'blessing', 'he', 'guided', 'enough', 'good', 'swallows', 'strongest', '18', 'water', 'rrrr', 'called', 'an', 'table', 'try', 'Ho', 'forward', 'never', 'time-a', 'suit', 'Throw', 'today', 'tap-dancing', 'those', 'what', 'outdoors', 'depart', 'With', 'lost', 'high', 'clap', 'wound', 'She', 'Woa', 'thump', 'masses', 'let', 'mad', 'magne', 'If', 'roar', 'five', 'Bravely', 'us', 'BROTHER', 'evil', 'oral', 'Here', 'particularly', 'course', 'repressed', 'Iiiiives', 'dappy', 'diaphragm', 'silly', 'Aaagh', 'straight', 'Most', 'va.', 'On', 'nineteen-and-a-half', \"'Dennis\", 'officer', 'eis', 'will', 'Are', 'little', 'outside', 'Hah', 'There', 'along', 'much', \"'sorry\", 'Monsieur', 'until', 'Stop', 'Huyah', 'o', 'demand', \"'Here\", 'Schools', 'snap', 'PRINCESS', 'nibble', 'He', 'marry', 'Nothing', 'properly', 'underwear', 'should', 'this', 'covered', 'in', 'i', 'foul', 'fwump', 'Spring', 'CRONE', 'into', 'Divine', 'ye', 'chops', 'birds', 'joyful', 'might', 'government', 'seldom', 'vicious', 'together', 'length', 'asks', 'talk', 'Herbert', 'Of', 'bringing', 'brave', 'court', 'strange', 'git', 'alarm', 'hat', 'One', 'am', 'Beast', \"'ve\", 'south', '22', 'Amen', 'stupid', 'passed', 'entrance', 'that', 'empty', 'Dramatically', 'need', 'So', 'plover', 'lovely', 'laden', 'Silly', 'havin', 'ferocity', 'body', 'thing', 'And', 'Aauuugh', 'high-pitched', 'nick', 'fatal', 'b', 'CROWD', 'vests', 'Grail', 'settles', 'commands', 'died', 'yourself', 'who', 'class', 'Hill', 'then', 'Winston', 'TIM', 'round', 'lord', 'elderberries', 'sweet', 'Bones', 'Aah', 'What', 'Nu', 'up', 'bint', 'Lake', 'Chapter', 'employed', 'changed', 'dead', 'BRIDE', 'its', 'ooh', 'bravest', 'lies', 'chord', 'hear', 'witch', '21', 'PRISONER', 'Ni', 'buy', 'having', 'starling', 'Who', '23', 'become', 'decision', 'Now', 'outrageous', 'drilllll', 'ARMY', 'with', 'noise', 'they', 'Maynard', 'Robinson', 'unsingable', 'liver', 'zoosh', 'ju', \"'e\", 'forget', 'stay', 'Pendragon', 'chastity', 'Pull', 'thwonk', 'put', 'derives', 'Mercea', 'ignore', 'tiny', 'weight', 'say', 'merger', 'hiyaah', 'given', 'hee', 'any', 'Hurry', 'taking', 'nobody', 'acting', 'limbs', 'African', 'splat', 'every', 'attack', 'samite', 'waste', 'anything', 'Old', 'de', 'tale', 'required', 'dine', 'girl', 'guiding', 'bottom', \"'O\", 'wise', 'twenty', 'Lucky', 'migrate', 'Aaaugh', ',', 'leave', 'GUARDS', 'courage', 'Use', 'hand', 'DIRECTOR', 'nice', 'persons', 'swords', 'quests', 'pond', 'OF', 'Heh', 'Mmm', 'actually', 'scene', 'medical', 'reasonable', 'ever', 'Bedwere', 'Thou', 'getting', 'country', 'saved', 'True', 'raised', 'fooling', 'haste', 'period', 'food', 'trouble', 'twang', 'single-handed', 'bad-tempered', 'domine', 'just', 'dull', 'c', 'sun', 'Behold', 'Ayy', 'why', 'snore', 'martin', 'Just', 'VILLAGER', 'chance', 'carries', 'liege', 'ham', 'sponge', 'minute', 'working', 'door', 'clack', 'HISTORIAN', \"'Oooooooh\", 'could', 'Ohh', 'counting', 'Lord', 'time', 'cope', 'boom', 'stood', 'owns', '#', 'groveling', 'Pie', 'woosh', 'find', 'biscuits', 'sex', 'imprisoned', 'icy', 'Lie', 'Ninepence', 'exploiting', 'plain', 'outwit', 'Stand', 'shut', 'BRIDGEKEEPER', 'brain', 'Tall', 'Charge', 'hospitality', 'clunk', 'Eee', 'Bridge', 'come', 'tropical', 'speak', 'north', 'RANDOM', 'regulations', 'going', 'mooooooo', 'dictating', 'helpful', 'wants', 'Fetchez', 'Run', 'guard', 'well', 'beside', 'PIGLET', 'defeat', 'Since', 'leap', 'Practice', 'tree', 'blood', 'outdated', 'Great', 'heard', 'Bedevere', 'armed', 'Aaauugh', 'problems', 'Is', 'presence', 'Sir', 'pen', 'SHRUBBER', 'thirty-seven', 'give-away', 'sawwwww', 'yes', 'internal', 'forced', 'sheep', \"'is\", 'VOICE', 'Dis-mount', 'great', 'Lady', 'lapin', 'Chaste', 'blanket', 'forty-three', 'house', 'does', 'ptoo', 'dying', 'whispering', 'most', 'Nador', 'sonny', 'cheesy', 'sod', \"'I\", 'wedlock', 'Ives', 'went', 'hopeless', 'ehh', 'Mind', 'guests', 'Anarcho-syndicalism', 'Steady', 'name', 'Hya', 'split', 'was', 'valleys', \"'s\", 'squeak', 'lad', 'profane', 'needs', 'no', 'thank', 'mac', 'bugger-folk', 'Brother', 'MINSTREL', 'Once', 'done', 'else', 'bonk', 'You', 'for', 'by', \"d'you\", 'As', 'Huy', 'particular', \"'forgive\", 'asking', 'spake', \"n't\", 'also', 'Looks', 'climes', 'use', 'HEAD', 'writing', 'answer', 'carrying', 'wan', 'creak', 'streak', 'rope', '.', 'score', 'electric', 'breath', 'Olfin', 'conclusion', 'dangerous', 'holy', 'Uh', 'beat', 'ways', 'Hoa', 'heeh', 'scots', 'MIDGET', 'Four', 'self-perpetuating', 'minutes', 'Splendid', 'enter', 'retreat', 'something', 'O', 'fourth', 'tracts', 'bed-wetting', 'met', 'take', 'plan', 'fair', 'under', 'wide', 'mandate', 'WINSTON', 'Guards', 'give', 'inherent', 'ponds', 'worked', 'Yeah', 'cross', 'understanding', 'uuup', 'look', 'tell', 'Order', 'heh', 'death', 'sure', 'Hmm', 'sigh', 'lying', 'example', 'nightfall', 'w', 'bridges', 'Must', 'so', 'bunny', 'RIGHT', 'Torment', 'Wood', 'fart', 'Saxons', 'pull', 'castanets', \"'Ecky-ecky-ecky-ecky-pikang-zoop-boing-goodem-zoo-owli-zhiv\", 'line', 'lonely', 'whom', 'act', 'Running', 'Zoot', 'Nine', 'Mud', 'Listen', 'frighten', 'very', '3', 'Hold', 'fruit', 'floats', 'back', 'That', 'Dennis', 'Angnor', 'chest', 'maintain', 'impersonate', 'Go', 'mud', 'rocks', 'looks', 'Together', 'social', 'land', 'averting', 'FATHER', 'mile', 'built', \"'Ni\", 'Battle', 'howl', 'indeed', 'flesh', 'repressing', 'been', 'Aaah', 'GALAHAD', 'idiom', 'nervous', 'clllank', 'donaeis', 'me', 'brush', 'indefatigable', 'held', 'g', \"'shrubberies\", 'arrows', 'leaps', 'late', 'Ahh', 'MIDDLE', 'meeting', 'Said', 'CRASH', 'around', 'mate', 'son', 'main', 'apologise', 'stop', 'grip', 'rode', 'Chop', 'Until', 'vary', 'BLACK', 'Nay', 'Antioch', 'visually', 'unladen', 'DINGO', 'committed', 'Dingo', 'bond', 'mooo', \"'Morning\", 'task', 'path', 'uhh', 'AMAZING', 'dub', 'hang', 'handle', 'fellows', '7', 'DENNIS', 'Thy', 'Hello', 'Iesu', 'if', 'grips', 'CUSTOMER', 'PERSON', 'nose', 'LOVELY', 'safety', 'Pin', 'Britons', 'Crapper', 'Umm', \"'Ere\", 'Thank', 'farcical', 'out-clever', 'aaaaaah', 'kneecaps', 'enchanter', 'wedding', 's', 'beacon', 'two-thirds', 'room', 'Midget', 'spam', 'four', '12', 'Yapping', 'Three', 'parts', '--', 'feathers', 'bastards', 'least', 'passing', 'sloths', 'badger', 'Caerbannog', 'Gable', 'Churches', 'ask', 'kills', 'heh..', 'still', 'Action', 'Cut', 'BEDEVERE', 'second', 'decided', 'get', 'less', 'Even', 'rodent', 'business', 'Frank', 'shit', 'cost', 'our', 'sacrifice', 'Thpppt', 'bad', 'bicker', 'small', 'bold', 'doubt', 'power', 'creeper', 'new', 'animator', 'chorus', 'liar', 'awaaaaay', 'CART-MASTER', 'Hee', 'approaching', 'harmless', 'tear', 'Joseph', 'Um', 'Augh', 'somewhere', 'fell', 'off', 'returns', 'certainly', 'town', 'No', 'hospital', 'unplugged', 'baaaa', 'eh', 'saying', 'scimitar', 'knock', 'life', 'opera', 'far', 'immediately', 'Aaaaugh', 'flint', 'dynamite', 'seems', 'told', 'wield', 'feet', 'See', 'Ooh', 'LUCKY', 'Help', 'Forward', 'islands', 'to', 'middle', 'Let', 'warned', 'bleed', 'mine', 'Firstly', 'hills', 'Uuh', 'orangutans', 'through', 'Huh', 'Ector', 'KNIGHTS', 'gallantly', 'trough', 'sometimes', 'crash', 'Welcome', 'sons', 'eccentric', 'such', 'distributing', 'MAYNARD', 'grail-shaped', 'But', 'hoo', 'biggest', 'other', 'string', 'rescue', 'awaits', 'science', 'hundred-and-fifty', 'oh', 'Aaaaaah', 'almost', 'hmm', 'conclusions', 'wiper', 'vache', 'siren', 'uh', 'understand', 'dungeon', 'door-opening', 'illegitimate-faced', 'arms', \"'To\", 'things', 'dorsal', 'headoff', 'run', 'shimmering', 'Thppt', 'HERBERT', 'unhealthy', 'Shut', 'gravy', 'tired', 'learning', 'question', 'Waa', \"'Erbert\", 'woman', 'wait', 'protect', 'auuuuuuuugh', \"'uuggggggh\", 'sent', 'etc', \"C'est\", 'ROGER', 'Almighty', 'bi-weekly', 'night', 'splash', 'mayest', 'travellers', 'not', 'Other', 'word', 'strangers', 'times', 'glad', 'servant', 'KING', 'worst', 'place', 'foe', 'approacheth', 'war', 'separate', 'beds', 'sir', 'right', 'WOMAN', 'stone', 'leg', 'creep', 'utterly', 'Oui', 'nostrils', 'oooh', 'pestilence', 'ugly', 'women', 'lose', 'sample', 'dirty', 'knocked', 'best', 'tragic', 'now', 'I', 'wind', 'Will', 'bum', 'doors', 'head', 'OTHER', 'wishes', 'slightly', 'charged', 'alight', 'please', 'afoot', 'of', 'mean', 'influential', 'Those', 'bid', 'lair', 'Get', 'Whoa', 'day..', 'DEAD', 'turned', 'CHARACTER', 'Camaaaaaargue', 'pray', 'Surely', 'push', 'Gallahad', 'mumble', 'pweeng', 'attend', 'Keep', 'build', 'couple', 'n', 'cough', 'wounded', 'keen', 'lads', 'Hand', 'WIFE', 'miserable', 'either', 'bastard', 'cover', 'king-a', 'third', 'full', 'scales', 'types-a', 'wo', 'training', 'order', 'Dappy', 'formidable', 'wicked', 'carp', 'test', 'quite', 'glass', 'NI', 'north-east', 'words', 'U', 'answers', 'escape', 'horn', 'have', 'Actually', 'carving', 'them', 'duck', 'note', 'undressing', 'Ridden', \"'cause\", 'na', 'l', 'wrong', 'humble', 'oo', 'witness', 'ill.', 'man', 'vote', 'N', 'Thee', 'flight', 'Anyway', 'bathing', 'said', 'eisrequiem', 'running', 'your', 'forest', 'scrape', 'burst', 'u', 'down', 'wipers', 'busy', 'alive', 'about', 'sad', 'removed', 'riding', 'over', 'voluntarily', 'mother', 'Why', 'really', 'Round', 'exciting', 'performance', 'To', 'ordinary', 'agree', '6', 'real', 'ladies', 'auntie', 'coming', 'knew', 'bother', 'eat', 'keeper', 'eyes', \"'Aauuuuugh\", 'killer', 'Like', 'Everything', 'trusty', 'His', 'effect', 'The', 'pause', 'Death', 'uuggggggh', 'Hic', 'these', 'Summer', 'mayhem', 'looking', 'Too', 'heroic', 'Supposing', 'largest', 'Quoi', 'ENCHANTER', 'Prepare', 'defeator', 'Hey', 'fallen', 'laughing', 'pimples', 'dogma', 'sorry', 'his', 'collective', 'wounding', 'stayed', 'inferior', 'hall', 'bows', 'scribble', 'OFFICER', 'donkey-bottom', 'Never', 'better', 'Wayy', 'accompanied', ':', 'Every', 'able', 'remembered', 'yet', 'awhile', 'Halt', 'warning', 'awfully', 'lunged', 'has', 'remember', 'perilous', 'sing', 'cruel', 'mystic', 'felt', 'examine', 'Have', 'Blue', 'Yup', 'hello', 'young', 'supposed', 'sister', 'anchovies', 'doing', 'preserving', 'left', 'air-speed', 'Ah', 'crying', 'differences', 'miss', \"'First\", 'watery', 'day', 'Eh', '17', 'there', \"'Course\", 'seem', 'throughout', 'forth', 'follow', \"'d\", 'first', 'everything', 'person', 'INSPECTOR', 'spank', \"'Man\", 'consulted', 'prevent', 'naughty', 'Aggh', 'Shrubber', 'entered', 'clad', 'thought', '19', 'Where', 'sink', 'aaugh', 'afraid', \"'anging\", 'grovel', 'present', 'thine', 'workers', 'la', 'Mother', 'knights', 'turns', 'we', 'sell', 'rejoicing', 'nearer', 'violence', 'ran', 'singing', 'They', 'last', 'soft', 'Cherries', 'behind', 'biters', 'weapon', ']', 'count', 'gra', 'Aaaaaaaaah', 'cut', 'Book', 'old', 'Therefore', 'VILLAGERS', 'Defeat', 'yours', 'pansy', 'supreme', 'risk', \"'it\", 'Guy', 'un', 'ethereal', 'saw', 'kingdom', 'bottoms', 'cry', '4', 'accomplished', 'each', \"'em\", 'and', 'men', '9', 'dear', 'even', 'spanking', 'Clark', 'near', 'classes', 'baby', 'For', 'bridgekeeper', 'bowels', 'sire', \"'ll\", 'Yay', 'tinder', 'appease', 'Tower', 'quest', 'CAMERAMAN', 'aquatic', 'easy', 'raped', 'French', 'pass', 'CARTOON', 'bois', 'Patsy', 'him', 'pig', 'sixteen', 'bride', 'LAUNCELOT', 'search', 'soiled', 'economic', 'at', 'Not', 'Bloody', 'twin', 'Uugh', 'Farewell', 'year', 'Does', 'retold', 'maybe', 'avenged', 'carved', 'formed', 'England', 'Recently', 'you', 'Back', 'SUN', 'known', 'swamp', 'Not-appearing-in-this-film', 'Honestly', 'are', 'verses', 'handsome', 'punishment', 'strategy', 'disheartened', 'SCENE', 'bird', 'says', 'rabbit', 'sight', 'beyond', 'band', 'ARTHUR', 'delirious', 'Himself', 'knows', 'goes', 'Thpppppt', 'This', 'W', 'it', 'mangled', 'Hiyya', 'autonomous', 'Off', 'feel', 'logically', 'depressing', 'return', 'sense', 'were', 'help', 'go', 'Uhh', 'wet', 'ANIMATOR', 'Two', 'winter', 'wood', 'strength', 'point', 'scenes', 'Clear', 'Hm', 'bats', 'castle', 'the', 'Bravest', 'eet', 'bangin', 'assist', 'boil', 'bed', 'arrange', 'union', 'worry', 'Un', 'traveller', 'ones', 'therefore', 'shows', 'scholar', 'radio', 'Uther', 'packing', 'reads', 'Good', 'is', 'Heee', 'her', 'carve', 'tea', 'Oooo', 'gouged', 'bloody', 'Hiyaah', 'bless', 'capital', 'non-migratory', 'suggesting', 'married', '11', 'how', 'command', 'window-dresser', 'nearly', 'worse', 'Table', 'supports', 'somebody', 'named', 'mashed', 'GREEN', 'again', 'Oh', 'valiant', 'Come', 'broken', 'buggered', 'took', 'Very', 'European', 'Be', 'Yeaah', 'tough', 'resumes', 'dress', 'object', 'Wait', 'Thursday', 'Cider', 'Britain', 'cave', 'mangy', 'ninepence', 'art', 'GUESTS', 'clear', 'Walk', 'ca', 'teeth', 'more', 'Court', 'banana-shaped', 'Doctor', 'Concorde', 'eight', 'guards', 'bridge', 'Allo', 'Bad', 'Hallo', 'temptation', 'Away', 'started', 'Badon', 'suspenseful', 'haaa', 'CRAPPER'}\n"
     ]
    }
   ],
   "source": [
    "# Make a set of unique tokens in the entire scene: unique_tokens\n",
    "unique_tokens = set(word_tokenize(scene_one))\n",
    "\n",
    "# Print the unique tokens result\n",
    "print(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580 588\n"
     ]
    }
   ],
   "source": [
    "# Search for the first occurrence of \"coconuts\" in scene_one: match\n",
    "match = re.search(\"coconuts\", scene_one)\n",
    "\n",
    "# Print the start and end indexes of match\n",
    "print(match.start(), match.end())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(9, 32), match='[wind] [clop clop clop]'>\n"
     ]
    }
   ],
   "source": [
    "# Write a regular expression to search for anything in square brackets: pattern1\n",
    "pattern1 = r\"\\[.*\\]\"\n",
    "\n",
    "# Use re.search to find the first text in square brackets\n",
    "print(re.search(pattern1, scene_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 7), match='ARTHUR:'>\n"
     ]
    }
   ],
   "source": [
    "# Find the script notation at the beginning of the fourth sentence and print it\n",
    "pattern2 = r\"[\\w\\s]+:\"\n",
    "print(re.match(pattern2, sentences[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# advanced tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- OR is represented using |\n",
    "- define a group using () for a explicit set of characters\n",
    "- define explicit character ranges using []\n",
    "- (escape character) use \\ (backward slash) in front of - (hifen) or . (period)\n",
    "- use .* as a wildcard\n",
    "- use + or * for a greedy match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He', 'has', '11', 'cats']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_digits_and_words = ('(\\d+|\\w+)')\n",
    "re.findall(match_digits_and_words, 'He has 11 cats.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regex ranges and groups\n",
    "pattern                                matches                               example\n",
    "[A-Za-z]+                 upper and lowercase English alphabet            'ABCDEFghijk'\n",
    "[0-9]                             numbers from 0 to 9                           9\n",
    "[A-Za-z\\-\\.]+          upper and lowercase English alphabet, -and .      'My-Website.com'\n",
    "(a-z)                               a, - and z                                'a-z'\n",
    "(\\s+l,)                           spaces or a comma                           ', '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 35), match='match lowercase spaces nums like 12'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str = 'match lowercase spaces nums like 12, but no commas'\n",
    "re.match('[a-z0-9 ]+', my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"SOLDIER #1: Found them? In Mercea? The coconut's tropical!\"\n",
    "pat1 = r\"\\w+(\\?!)\"\n",
    "pat2 = r\"(\\w+|#\\d|\\?|!)\"\n",
    "pat3 = r\"(#\\d\\w+\\?!)\"\n",
    "pat4 = r\"\\s+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SOLDIER',\n",
       " '#1',\n",
       " 'Found',\n",
       " 'them',\n",
       " '?',\n",
       " 'In',\n",
       " 'Mercea',\n",
       " '?',\n",
       " 'The',\n",
       " 'coconut',\n",
       " 's',\n",
       " 'tropical',\n",
       " '!']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tokenize(string,pat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = 'This is the best #nlp exercise ive found online! #python', '#NLP is super fun! <3 #learning', 'Thanks @datacamp :) #nlp #python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#nlp', '#python']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a regex pattern to find hashtags: pattern1\n",
    "pattern1 = r\"#\\w+\"\n",
    "\n",
    "# Use the pattern on the first tweet in the tweets list\n",
    "regexp_tokenize(tweets[0], pattern1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@datacamp', '#nlp', '#python']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a pattern that matches both mentions and hashtags\n",
    "pattern2 = r\"([@#]\\w+)\"\n",
    "\n",
    "# Use the pattern on the last tweet in the tweets list\n",
    "regexp_tokenize(tweets[-1], pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['This', 'is', 'the', 'best', '#nlp', 'exercise', 'ive', 'found', 'online', '!', '#python'], ['#NLP', 'is', 'super', 'fun', '!', '<3', '#learning'], ['Thanks', '@datacamp', ':)', '#nlp', '#python']]\n"
     ]
    }
   ],
   "source": [
    "# Use the TweetTokenizer to tokenize all tweets into one list\n",
    "tknzr = TweetTokenizer()\n",
    "all_tokens = [tknzr.tokenize(t) for t in tweets]\n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_text = \"Wann gehen wir zum Pizza? 🍕 Und fährst du mit Über? 🚕\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wann', 'gehen', 'wir', 'zum', 'Pizza', '?', '🍕', 'Und', 'fährst', 'du', 'mit', 'Über', '?', '🚕']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and print all words in german_text\n",
    "all_words = word_tokenize(german_text)\n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wann', 'Pizza', 'Und', 'Über']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and print only capital words\n",
    "capital_words = r\"[A-ZÜ]\\w+\"\n",
    "print(regexp_tokenize(german_text, capital_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['🍕', '🚕']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and print only emoji\n",
    "emoji = \"['\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF']\"\n",
    "print(regexp_tokenize(german_text, emoji))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the script into lines:\n",
    "lines = scene_one.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24bf47f80f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace all script lines for speaker\n",
    "pattern = \"[A-Z]{2,}(\\s)?(#\\d)?([A-Z]{2,})?:\"\n",
    "lines = [re.sub(pattern, '', l) for l in lines]\n",
    "\n",
    "# Tokenize each line: tokenized_lines\n",
    "tokenized_lines = [regexp_tokenize(s,\"\\w+\") for s in lines]\n",
    "\n",
    "# Make a frequency list of lengths: line_num_words\n",
    "line_num_words = [len(t_line) for t_line in tokenized_lines]\n",
    "\n",
    "# Plot a histogram of the line lengths\n",
    "plt.hist(line_num_words)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
